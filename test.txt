========課題１========

機械学習に関する基礎知識

工学部 電子情報学科
学籍番号：08D23091
辻 孝弥

1. Accuracy, Precision, Recall, F1-score の計算式

混同行列（Confusion Matrix）の要素：
・TP (True Positive): 真陽性 - 正しく正と予測された数
・TN (True Negative): 真陰性 - 正しく負と予測された数
・FP (False Positive): 偽陽性 - 誤って正と予測された数
・FN (False Negative): 偽陰性 - 誤って負と予測された数

Accuracy（正解率）
計算式: (TP + TN) / (TP + TN + FP + FN)
説明：全体のデータの中で、正しく予測できた割合を表す。

Precision（適合率）
計算式: TP / (TP + FP)
説明：正と予測したデータの中で、実際に正であった割合を表す。

Recall（再現率）
計算式: TP / (TP + FN)
説明：実際に正であるデータの中で、正と予測できた割合を表す。

F1-score（F1値）
計算式: 2 * (Precision * Recall) / (Precision + Recall)
説明：Precision と Recall の調和平均である。両者のバランスを考慮した指標で、どちらか一方だけが極端に高い場合に低い値になる。クラスの偏りが大きいデータセットでAccuracyよりも有用である。

2. deepcopy と copy 関数の違い

・copy: オブジェクトの参照をコピーする。元のオブジェクトとコピーされたオブジェクトは、同じデータを参照するため、一方を変更するともう一方も変更される。

・deepcopy: オブジェクトとその内部のオブジェクトも含めて、すべてを新たにコピーする。元のオブジェクトとコピーされたオブジェクトは完全に独立しており、一方を変更してももう一方に影響はない。

3. optimizer.zero_grad() の有無による動作の違い

optimizer.zero_grad() は、モデルのパラメータの勾配を0にリセットする関数である。

optimizer.zero_grad() がある場合：
各 iteration（バッチ）の前に勾配が0にリセットされるため、勾配が累積されずに、現在のバッチのデータに基づいてパラメータが更新される。

optimizer.zero_grad() がない場合：
・勾配が iteration 毎に累積されていく。
・過去の勾配情報が現在の更新に影響を与えるため、学習が不安定になったり、意図した方向に学習が進まなかったりする可能性がある。

影響：
optimizer.zero_grad() を実行しないと、以下のような問題が生じる可能性がある：
・loss が発散しやすくなる
・モデルの学習速度が遅くなる
・モデルが収束しなくなる

結論：
optimizer.zero_grad() は、各 iteration の前に勾配をリセットすることで、安定した学習を保証するために必要な処理である。 

参考文献
・Google Developers: Machine Learning Crash Course - Classification: Accuracy, Precision, Recall
  https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall?hl=ja




========課題2========

1. 処理のまとまりを作った
データの読み込み、前処理、分割、モデル訓練などをそれぞれ別の関数にした。
可読性向上のため

2. 使う特徴を工夫した
まず、モデルがあまり使わない特徴を自動的に取り除いた。

逆に大事な値（priors_count や age）は残すようにした。

「１年あたりの前科件数」や「年齢×前科件数」など、独自に「新しい特徴量」も足して、モデルが学びやすくした。

3. ２つのモデルを作って比べた
XGBoost（木を使うモデル）
学習の強さや深さなどの設定を自動で調整している。(Optuneを使用)

Early Stoppingを使用して、過学習を防いでいる。


MLP
入力サイズを自由に変えられる設計にした。

各層にバッチ正規化とドロップアウトを入れて、安定して学習でき、過学習も減らせる。

データの偏りに合わせて損失関数に重みをつけ、不利なクラスも学べるようにした。

学習率を段階的に変えるスケジューラを使い、効率よく学習させた。

検証データの損失が改善しなくなったら、自動で学習を止める。


4. ２つの結果を合わせて最後の判断をした
XGBoost と MLP の予測確率を合わせて、新しくロジスティック回帰で学び直す（スタッキング）。


5. 全体的なアーキテクチャを図にしてみた

データ準備 ─▶ XGBoost 学習 ┐
         │                  ├▶ スタッキング ─▶ 最終予測
         └▶ MLP 学習 ───────┘





========課題３========

高精度を出すためにどのような工夫を行ったか
本課題では、高い予測精度を得るために、以下の2つの主な手法と戦略を用いて取り組んだ。

使用手法
TabNet

Optuna（ハイパーパラメータ最適化ライブラリ）

工夫1：TabNetの導入による高精度なモデル構築
従来のニューラルネットワーク（多層パーセプトロン）では特徴量の解釈性や学習効率に限界があったため、より表形式データに適した深層学習モデル「TabNet」を導入した。T

実験では、PyTorchベースのTabNetライブラリ（pytorch-tabnet）を使用し、既存のPyTorch環境に容易に統合した。

工夫2：Optunaによるハイパーパラメータ最適化
モデルの性能向上のために、Optunaを用いた自動ハイパーパラメータチューニングを実施した。

学習率（learning rate）

エポック数（max_epochs）

重み減衰（weight_decay）

バッチサイズ

TabNet固有のパラメータ（n_d, n_a, n_stepsなど）

これらのパラメータについて、Optunaによるベイズ最適化を適用し、探索回数を多めに設定することで精度向上を狙った。

戦略：時間よりも精度を優先する方針
モデルの実行時間が多少長くなってもよいという前提のもと、チューニングプロセスに時間をかける方針をとった。特にOptunaの試行回数（trials）を増やし、学習の繰り返し回数を高めることで、最適なパラメータセットの探索を実現した。

この戦略により、人力でパラメータチューニングするよりも効率的に行うことができ、バリデーション精度および最終的なテスト精度の向上を確認できた。

結果
TabNet + Optunaを用いた結果、以下の点で明確な改善が見られた：

モデルの精度が向上

過学習の抑制

特徴量ごとの重要度の把握が可能に

精度：
入力次元数：